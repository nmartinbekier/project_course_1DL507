{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fabcbc11-10c2-4c2e-8046-a31603104d97","showTitle":false,"title":""}},"outputs":[],"source":["import pandas as pd\n","import dlt\n","from pyspark.sql.functions import *\n","import pyspark.pandas as ps\n","#from trase.tools.aws.aws_helpers_cached import get_pandas_df_once\n","#from trase.tools.aws.metadata import write_csv_for_upload\n","spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\")\n","spark.conf.set(\"spark.databricks.delta.schema.overwriteSchema.enabled\",\"true\")\n","#spark.conf.set(\"spark.sql.execution.arrow.pyspark.fallback.enabled\",\"false\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6afb3374-d1a2-431f-97c2-1ebb811c8291","showTitle":false,"title":""}},"outputs":[],"source":["def get_pandas_df_once( key,\n","    bucket=\"s3a://uutrase/data/trase-uppsala/\",\n","    version_id=None,\n","    client=None,\n","    track=True,\n","    sep=\";\",\n","    encoding=\"utf8\",\n","    xlsx=False,\n","    **kwargs,):\n","    table_name = key.split(\".\")[0].split(\"/\")[-1]\n","    return ps.DataFrame(dlt.read(table_name)).to_pandas()\n","\n","def get_df_once( key,\n","    bucket=\"s3a://uutrase/data/trase-uppsala/\",\n","    version_id=None,\n","    client=None,\n","    track=True,\n","    sep=\";\",\n","    encoding=\"utf8\",\n","    xlsx=False,\n","    **kwargs,):\n","    table_name = key.split(\".\")[0].split(\"/\")[-1]\n","    return ps.DataFrame(dlt.read(table_name)).to_pandas()\n","    \n","\n","def get_df(key,bucket=\"s3a://uutrase/data/trase-uppsala/\",version_id=None,client=None,track=True,sep=\";\",encoding=\"utf8\",xlsx=False,**kwargs):\n","    \"\"\"\n","    Read a CSV or XLSX dataset from S3 to a Pandas DataFrame. See\n","    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n","    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n","    \"\"\"\n","    #@dlt.table(name=key.split(\".\")[0].split(\"/\")[-1])\n","    #def create_table():\n","    if xlsx:\n","        #return read_xlsx(key, bucket, version_id, client, track, **kwargs)\n","        return spark.read.format(\"com.crealytics.spark.excel\").option(\"delimiter\",sep).option(\"encoding\",encoding).option(\"header\",\"true\").option(\"multiline\",\"true\").load(bucket+key)\n","\n","    else:\n","        return spark.read.option(\"delimiter\",sep).option(\"encoding\",encoding).option(\"header\",\"true\").option(\"multiline\",\"true\").csv(bucket+key)\n","            #return read_csv(\n","        #    key, bucket, version_id, client, track, sep=sep, encoding=encoding, **kwargs\n","       # )\n","    \n","def write_csv_for_upload( df: \"pd.DataFrame\",\n","    key: str,\n","    script_path: str = None,\n","    path: str = None,\n","    metadata_path: str = None,\n","    metadata_key: str = None,\n","    bucket: str = \"trase-storage\",\n","    do_upload: bool = None,\n","    upstream = None,\n","    **pd_to_csv_kwargs,):\n","    \n","    pass\n","    \n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2b79c5a1-2e96-4098-b00d-f2ba90cf1133","showTitle":false,"title":""}},"outputs":[],"source":["\"\"\"\n","Method 2.\n","Industry (SeafoodTIP) and government sources tell us that exports are 95% of production.\n","Therefore we divide by 0.95.\n","This spreads the estimate of the total production (rather than just the exports) across the ponds, proportional to their area.\n","<< Eqn: production = ((pond_area/total_area))*exports_for_year)/0.95  >>\n","\n","This is given in columns: AVG_PROD_2013 ... to 2019\n","\"\"\"\n","\n","def run_script_combined():\n","    \n","    HS_CODES = [\"030616\", \"030617\", \"030635\", \"030636\", \"030695\", \"160521\", \"160529\"]\n","\n","\n","    def process(df, flows_df):\n","        _exports_for_year = flows_df[\"volume_raw\"].sum()\n","        _total_area = df[\"AREA_HA\"].sum()\n","\n","        def get_production(area_of_pond):\n","            return ((_exports_for_year / 0.95) / _total_area) * area_of_pond\n","\n","        df[\"avg_produced_tons\"] = df[\"AREA_HA\"].apply(get_production)\n","        df[\"avg_remaining_tons\"] = df[\"avg_produced_tons\"]\n","\n","        return df\n","\n","    pond_df = get_pandas_df_once(\n","        \"ecuador/production/crop_maps/production/shrimp_pond_maps/out/ec_shrimp_ponds.csv\"\n","    )\n","    pond_df.AREA_HA = pond_df.AREA_HA.astype(float)\n","\n","    combined = []\n","    YEARS = list(range(2013, 2020))\n","    for year in YEARS:\n","        flows_df = get_pandas_df_once(\n","            f\"ecuador/trade/cd/export/{year}/CD_ECUADOR_{year}.csv\",\n","            dtype=str,\n","            keep_default_na=False,\n","        )\n","        flows_df = flows_df.rename(\n","            columns={\n","                \"TOTAL.Net.Weight..Kg.\": \"volume_raw\",\n","                \"Harmonized.Code.Product.Spanish\": \"hs6\",\n","            },\n","            errors=\"raise\",\n","        )\n","        flows_df = flows_df[flows_df[\"hs6\"].isin(HS_CODES)]\n","        flows_df[\"volume_raw\"] = flows_df.volume_raw.astype(float)\n","        flows_df[\"volume_raw\"] /= 1_000\n","        out_df = process(pond_df, flows_df)\n","        #print(year, out_df[\"avg_produced_tons\"].sum())\n","        out_df = out_df[\n","            [\n","                \"POND_TRASE_ID\",\n","                \"PARISH_TRASE_ID\",\n","                \"AREA_HA\",\n","                \"avg_produced_tons\",\n","                \"avg_remaining_tons\",\n","            ]\n","        ]\n","        out_df = out_df.assign(YEAR=str(year))\n","\n","        # combine to output for parish\n","        cout_df = (\n","            out_df.groupby([\"PARISH_TRASE_ID\", \"YEAR\"])[[\"avg_produced_tons\", \"AREA_HA\"]]\n","            .sum()\n","            .reset_index()\n","        )\n","        assert cout_df[\"avg_produced_tons\"].sum() >= flows_df[\"volume_raw\"].sum()\n","        combined.append(cout_df)\n","        #print(\"cout_df\",cout_df)\n","\n","    combined_df = pd.concat(combined)\n","    \n","    write_csv_for_upload(\n","        combined_df,\n","        \"ecuador/production/crop_maps/production/shrimp_pond_maps/out/ec_production_per_parish.csv\",\n","    )\n","    print(ps.DataFrame(combined_df))\n","    return ps.DataFrame(combined_df)\n","def run_script_area():\n","    combined_df = get_df_once(\"ecuador/production/crop_maps/production/shrimp_pond_maps/out/ec_production_per_parish.csv\")\n","    print(\"asd: \",combined_df)\n","    area_df = combined_df[combined_df[\"YEAR\"] == \"2019\"]\n","    area_df = area_df[[\"PARISH_TRASE_ID\", \"AREA_HA\"]]\n","    write_csv_for_upload(\n","        area_df,\n","        \"ecuador/production/crop_maps/production/shrimp_pond_maps/out/ec_shrimp_area_per_parish.csv\",\n","    )\n","    return ps.DataFrame(area_df)\n","\n","YEARS = list(range(2013, 2020))\n","table_names = []\n","for year in YEARS:\n","    table_names += [f\"ecuador/trade/cd/export/{year}/CD_ECUADOR_{year}.csv\"]\n","table_names += [\"ecuador/production/crop_maps/production/shrimp_pond_maps/out/ec_shrimp_ponds.csv\"]\n","#for name in table_names:\n","#    @dlt.table(name = name.split(\".\")[0].split(\"/\")[-1])\n","#    def create_table():\n","#        return get_df(name)\n","def get_table_name(longname):\n","    return longname.split(\".\")[0].split(\"/\")[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"689495d1-54b5-4a03-b03c-3fb8e39ac1eb","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.types import *\n","\n","@dlt.table(name=get_table_name(table_names[0]))\n","def table0():\n","    return get_df(table_names[0])\n","@dlt.table(name=get_table_name(table_names[1]))\n","def table1():\n","    return get_df(table_names[1])\n","@dlt.table(name=get_table_name(table_names[2]))\n","def table2():\n","    return get_df(table_names[2])\n","@dlt.table(name=get_table_name(table_names[3]))\n","def table3():\n","    return get_df(table_names[3])\n","@dlt.table(name=get_table_name(table_names[4]))\n","def table4():\n","    return get_df(table_names[4])\n","@dlt.table(name=get_table_name(table_names[5]))\n","def table5():\n","    return get_df(table_names[5])\n","@dlt.table(name=get_table_name(table_names[6]))\n","def table6():\n","    return get_df(table_names[6])\n","@dlt.table(name=get_table_name(table_names[7]))\n","def table7():\n","    return get_df(table_names[7])\n","    \n","#,     \n","@dlt.table(name=\"ec_production_per_parish\",schema=\n","    StructType(\n","     [\n","        StructField('PARISH_TRASE_ID', StringType()),\n","        StructField('YEAR', StringType()),\n","        StructField('avg_produced_tons', DoubleType()),\n","        StructField('AREA_HA', DoubleType())\n","      ]\n","    ))\n","def eppp():\n","    return run_script_combined()\n","\n","@dlt.table(name=\"ec_shrimp_area_per_parish\")\n","def sapp():\n","    return run_script_area()    "]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"ec_shrimp_area_production_per_parish_rewrite","notebookOrigID":4155299916017783,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
